# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

WeFinance Copilot is an AI-powered financial assistant for the 2025 Shenzhen Fintech Competition. It uses Vision LLM (GPT-4o) for bill OCR, conversational AI for financial advice, and explainable AI for investment recommendations.

**Key Architecture Decision**: Originally used PaddleOCR, but migrated to GPT-4o Vision OCR for 100% recognition accuracy (vs 0% with synthetic images). This is the core competitive advantage.

**Project Status**: Competition-ready deployment. Live demo at https://wefinance-copilot.streamlit.app. Demo materials prepared (screenshots/, demo/wefinance_presentation.pptx).

**Deployment**: Primary deployment on Streamlit Community Cloud with automatic CI/CD from `main` branch. See DEPLOY.md for container deployment options.

## Essential Commands

### Environment Setup
```bash
# Activate conda environment (REQUIRED before any command)
conda activate wefinance

# First-time setup
conda env create -f environment.yml  # Create environment
pip install -r requirements.txt      # Development tools (pytest-cov, etc.)

# Update environment after modifying environment.yml
conda env update -f environment.yml --prune
```

**CRITICAL**: Always activate `conda activate wefinance` before running any command. System Python won't have required packages.

### Running the Application
```bash
# Standard mode (opens browser automatically)
streamlit run app.py --server.port 8501

# Background/headless mode
streamlit run app.py --server.port 8501 --server.headless true
```

Application opens at: `http://localhost:8501`

### Testing
```bash
# Run all tests
pytest tests/ -v

# Run specific test file
pytest tests/test_ocr_service.py -v

# Run single test function
pytest tests/test_ocr_service.py::test_vision_ocr_integration -v

# Run with coverage report
pytest --cov=modules --cov=services --cov=utils --cov-report=term-missing

# Generate HTML coverage report (opens htmlcov/index.html in browser)
pytest --cov=modules --cov=services --cov=utils --cov-report=html
```

### Code Quality
```bash
# Format code (REQUIRED before commits)
black .

# Lint code
ruff check .
ruff check --fix .  # Auto-fix safe issues
```

### Vision OCR Testing
```bash
# Simple test: Test Vision OCR with sample bills (uses assets/sample_bills/*.png)
python test_vision_ocr.py

# Expected: 100% recognition rate on all 3 sample bills

# Advanced batch testing: Test all bills with metadata validation
python scripts/test_vision_ocr.py --show-details --dump-json

# This validates against expected_transactions in metadata.json
# Results logged to: artifacts/ocr_test_results.log
# JSON dumps saved to: artifacts/ocr_results/*.json

# Test with real bill images (for production validation)
# Real bills located in assets/sample_bills/real/ (1.jpg, 2.png, 3.png, 4.png)
# These are actual photos/scans for realistic testing scenarios
```

### Deployment Commands

#### Streamlit Community Cloud (Current Production)
```bash
# No manual deployment needed - auto-deploys from GitHub on push to main
# Live URL: https://wefinance-copilot.streamlit.app

# Local preview before push
streamlit run app.py --server.port 8501

# Check logs on Cloud Dashboard: https://share.streamlit.io/
```

#### Docker Deployment (Optional)
```bash
# Build Docker image (for private cloud deployment)
docker build -t wefinance-copilot:latest .

# Run container
docker run -p 8501:8501 --env-file .env wefinance-copilot:latest

# Deploy to K8s (ACK/TKE/EKS)
kubectl apply -f k8s/deployment.yml
```

## Architecture Overview

### Core Innovation: Vision LLM Pipeline

**CRITICAL**: The OCR system underwent a major architectural shift:

```
Old (PaddleOCR): Image ‚Üí PaddleOCR ‚Üí Text ‚Üí GPT-4o ‚Üí Structured Data
New (Vision LLM): Image ‚Üí GPT-4o Vision ‚Üí Structured Data (ONE STEP)
```

**Why this matters**:
- PaddleOCR: 0% recognition on synthetic images, heavy dependencies (200MB models)
- Vision LLM: 100% recognition, zero additional dependencies, 2-5s per image
- **Implementation**: `services/vision_ocr_service.py` (161 lines)
- **Facade**: `services/ocr_service.py` maintains backward compatibility

### Data Flow Architecture

```
User Upload (pages/bill_upload.py)
    ‚Üì
OCRService.process_files()
    ‚Üì (delegates to)
VisionOCRService.extract_transactions_from_image()
    ‚îú‚îÄ Base64 encode image
    ‚îú‚îÄ GPT-4o Vision API call (temp=0.0, structured prompt)
    ‚îú‚îÄ JSON parsing ‚Üí Transaction objects
    ‚îî‚îÄ Return List[Transaction]
    ‚Üì
Session State (utils/session.py)
    ‚îú‚îÄ st.session_state["transactions"]
    ‚îî‚îÄ Shared across all pages
    ‚Üì
Multiple Consumers:
    ‚îú‚îÄ Advisor Chat (modules/chat_manager.py)
    ‚îú‚îÄ Investment Recommendations (services/recommendation_service.py)
    ‚îú‚îÄ Spending Insights (modules/analysis.py)
    ‚îî‚îÄ Anomaly Detection (modules/analysis.py::compute_anomaly_report)
```

### Session State Management

**CRITICAL PATTERN**: Streamlit `session_state` is the single source of truth. All data flows through `utils/session.py` helper functions.

```python
# CORRECT: Centralized state management
from utils.session import set_transactions, get_transactions

set_transactions(transactions)  # In bill_upload.py
transactions = get_transactions()  # In other pages

# WRONG: Direct session_state manipulation
st.session_state["transactions"] = transactions  # Bypasses validation/serialization
```

**Why use helpers**:
- Ensures consistent serialization (Transaction ‚Üí dict)
- Handles type normalization (dict ‚Üí Transaction)
- Provides single point of truth for state keys

**Key session state keys**:
- `transactions`: List[dict] - Serialized Transaction objects (core data)
- `chat_history`: List[dict] - Conversation messages
- `locale`: str - "zh_CN" or "en_US" (triggers full UI refresh on change)
- `monthly_budget`: float - User's budget (default: 5000.0)
- `anomaly_flags`: List[dict] - Active anomaly alerts
- `anomaly_history`: List[dict] - Resolved anomalies with user feedback
- `trusted_merchants`: List[str] - Whitelist for anomaly detection
- `i18n`: I18n - Lazy-loaded translation instance

### Error Handling System (NEW - 2025-11-09)

**Architecture**: Unified error handling with user-friendly messaging.

**Location**: `utils/error_handling.py`

**Key Components**:

1. **UserFacingError**: Exception type safe to display to end users
   - Contains user-friendly message
   - Optional suggestion for resolution
   - Preserves original technical error for logging

2. **@safe_call decorator**: Adds timeout protection and error conversion
   ```python
   from utils.error_handling import safe_call

   @safe_call(timeout=30, fallback=[], error_message="OCRËØÜÂà´Â§±Ë¥•")
   def process_image(image_bytes):
       # API call that might timeout or fail
       return llm_api_call(image_bytes)
   ```

3. **Automatic error mapping**:
   - Network errors ‚Üí "ÁΩëÁªúËøûÊé•‰∏çÁ®≥ÂÆö"
   - API auth errors ‚Üí "APIÂØÜÈí•ÈÖçÁΩÆÈîôËØØ"
   - Rate limits ‚Üí "APIË∞ÉÁî®Ê¨°Êï∞Ë∂ÖËøáÈôêÂà∂"
   - JSON parse errors ‚Üí "Êï∞ÊçÆÊ†ºÂºèËß£ÊûêÂ§±Ë¥•"

**Best practices**:
- Use `@safe_call` for all LLM API calls
- Set appropriate timeout (30s for vision, 15s for chat)
- Provide fallback values when graceful degradation is possible
- Custom error messages for domain-specific failures

### Persistent Storage System (NEW - 2025-11-09)

**Architecture**: File-based persistence for session data across browser refreshes.

**Location**: `utils/storage.py`

**Key Features**:
- JSON file backend (`~/.wefinance/data.json` by default)
- Automatic fallback to workspace if home directory is not writable
- Namespaced keys (`wefinance_` prefix)
- Thread-safe atomic writes

**Usage**:
```python
from utils.storage import save_to_storage, load_from_storage

# Save user preferences
save_to_storage("monthly_budget", 5000.0)

# Load with default fallback
budget = load_from_storage("monthly_budget", default=3000.0)
```

**Configuration**:
- Override storage path via `WEFINANCE_STORAGE_FILE` env variable
- Default paths (tried in order):
  1. `~/.wefinance/data.json` (preferred)
  2. `<workspace>/.wefinance/data.json` (fallback)

**When to use**:
- User preferences (budget, risk profile)
- Trusted merchant whitelist
- Anomaly detection history
- NOT for sensitive data (no encryption)

### LLM Integration Patterns

**Three LLM use cases**:

1. **Vision OCR** (`services/vision_ocr_service.py:60-160`):
   - Model: GPT-4o Vision
   - Input: Image bytes (base64 encoded)
   - Output: Structured JSON ‚Üí List[Transaction]
   - Temperature: 0.0 (deterministic)
   - Timeout: 30s (via @safe_call decorator)
   - Prompt engineering: Specifies exact JSON format, valid categories, date format
   - Error handling: Returns empty list on failure (graceful degradation)

2. **Chat** (`modules/chat_manager.py`):
   - Model: GPT-4o (text)
   - Input: User query + transaction context + budget context
   - Output: Natural language financial advice
   - Timeout: 15s (via @safe_call decorator)
   - Caching: Query-level LRU cache (20 items, exact string match)
   - Context assembly: `_assemble_context()` formats transactions for prompt

3. **Recommendations** (`services/recommendation_service.py`):
   - Model: GPT-4o (text)
   - Input: Transactions + risk profile + investment goal
   - Output: Structured recommendation with reasoning chain (explainable AI)
   - Timeout: 30s (via @safe_call decorator)
   - Caching: Streamlit `@st.cache_data` on deterministic inputs (transaction hash)

### Internationalization (i18n)

**Architecture**: Lazy-loaded translation system with fallback mechanism.

```python
# CORRECT: Get translations
from utils.session import get_i18n

i18n = get_i18n()
title = i18n.t("chat.title")  # Returns "Êô∫ËÉΩË¥¢Âä°È°æÈóÆ" or "AI Financial Advisor"

# Translation file structure
locales/zh_CN.json  # Chinese translations
locales/en_US.json  # English translations
utils/i18n.py       # Core I18n class (lazy-loads JSON, caches translations)
```

**Fallback chain**: `i18n.t(key)` ‚Üí locale file ‚Üí fallback locale ‚Üí key itself (if missing)

**Locale switching**:
```python
from utils.session import switch_locale
switch_locale("en_US")  # Updates session_state["locale"] + reloads I18n instance
# Triggers st.rerun() in app.py to refresh entire UI
```

**Implementation details**:
- JSON files: Nested dicts for namespacing (e.g., `"chat.title"`, `"app.welcome"`)
- Lazy loading: Files loaded on first `i18n.t()` call, cached in instance
- Session persistence: `st.session_state["i18n"]` persists I18n instance across reruns
- Cache invalidation: New I18n instance created on locale switch

### UI Components System (NEW - 2025-11-15)

**Architecture**: Reusable UI components for consistent visual experience across pages.

**Location**: `utils/ui_components.py`

**Key Components**:

1. **Financial Health Card**: Top status bar showing budget health
   ```python
   from utils.ui_components import render_financial_health_card

   # Render at top of page
   render_financial_health_card(transactions)
   ```

**Features**:
- Displays: Monthly budget, total spent, remaining balance, usage rate
- Color-coded health status:
  - üü¢ Healthy (< 60% usage)
  - üü° Good (60-85% usage)
  - üü† Warning (85-100% usage)
  - üî¥ Overspent (> 100% usage)
- Bilingual support via i18n system
- Gradient styling with shadow effects

**Usage Pattern**:
- Import component at page level (pages/spending_insights.py, pages/advisor_chat.py)
- Call after loading transactions from session state
- Automatically responsive to locale changes

## Critical Implementation Details

### Vision OCR Prompt Engineering

**Location**: `services/vision_ocr_service.py:77-96`

The prompt is carefully engineered for structured output:
- Specifies exact JSON format (no markdown code blocks)
- Lists valid categories: È§êÈ•Æ„ÄÅ‰∫§ÈÄö„ÄÅË¥≠Áâ©„ÄÅÂ®±‰πê„ÄÅÂåªÁñó„ÄÅÊïôËÇ≤„ÄÅÂÖ∂‰ªñ
- Requires YYYY-MM-DD date format
- Explicitly requests no markdown code blocks (but code handles them anyway)
- Returns empty array `[]` if no transactions found

**DO NOT** modify this prompt without testing against all sample bills in `assets/sample_bills/`.

**JSON parsing cleanup** (`vision_ocr_service.py:123-131`):
- Strips markdown code blocks: ````json` and `\`\`\``
- Handles malformed LLM responses gracefully
- Falls back to empty list on JSON parse failure

### Error Handling Philosophy

**Pattern**: Graceful degradation, not crash-and-burn.

```python
# Vision OCR failure ‚Üí Return empty list, allow manual input
from utils.error_handling import safe_call

@safe_call(timeout=30, fallback=[], error_message="OCRËØÜÂà´Â§±Ë¥•")
def extract_transactions(image):
    # API call
    return results
```

**Why**: User experience > perfect execution. Always provide a fallback path.

**User-facing error messages**:
- Translated via i18n system: `i18n.t("errors.api_key_missing")`
- Converted via `error_handling.py` for technical errors
- Logged at appropriate levels: `logger.error()`, `logger.warning()`, `logger.info()`
- Never expose API keys, stack traces, or internal details to users

## Deployment Architecture

### Current Production: Streamlit Community Cloud

**Live URL**: https://wefinance-copilot.streamlit.app

**Deployment Flow**:
```
Local Development ‚Üí Push to GitHub (main) ‚Üí Auto-deploy to Streamlit Cloud ‚Üí Live in 2-3 minutes
```

**Key Configuration**:
- **Secrets Management**: Via Streamlit Cloud Dashboard (Settings ‚Üí Secrets)
- **Environment**: Python 3.10, automatically managed by Streamlit Cloud
- **CI/CD**: Automatic on every push to `main` branch
- **Logs**: Available in Streamlit Cloud Dashboard (Settings ‚Üí Logs)

**Streamlit Cloud Secrets** (configured in Dashboard, not committed to git):
```toml
# .streamlit/secrets.toml (template in repo as secrets.toml.example)
OPENAI_API_KEY = "sk-your-api-key-here"
OPENAI_BASE_URL = "https://newapi.deepwisdom.ai/v1"
OPENAI_MODEL = "gpt-4o"
LLM_PROVIDER = "openai"
TZ = "Asia/Shanghai"
```

**Deployment Verification**:
1. Push code to `main` branch
2. Wait 2-3 minutes for auto-deployment
3. Check Streamlit Cloud Dashboard for build status
4. Test live app: Upload sample bill from `assets/sample_bills/`
5. If errors, check Dashboard ‚Üí Logs for stack traces

### Alternative Deployment: Docker + K8s

For private cloud deployment (internal networks, GPU nodes):

**Docker Build**:
```bash
# Create Dockerfile (example)
FROM python:3.10-slim
WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY . .
EXPOSE 8501
CMD ["streamlit", "run", "app.py", "--server.port=8501", "--server.headless=true"]
```

**Deploy to Kubernetes**:
```bash
# Build and push image
docker build -t wefinance-copilot:latest .
docker push your-registry/wefinance-copilot:latest

# Deploy with K8s manifest (k8s/deployment.yml)
kubectl apply -f k8s/deployment.yml
kubectl scale deployment wefinance-copilot --replicas=3  # HPA for traffic
```

**Private Cloud Benefits**:
- Data stays within company network (compliance)
- GPU acceleration for future ML features
- Custom resource allocation (8-core CPU + 32GB RAM + T4 GPU)
- Nginx reverse proxy for internal access

See DEPLOY.md for detailed deployment strategies.

## Configuration

### Required .env Variables
```bash
# OpenAI-compatible API (REQUIRED)
OPENAI_API_KEY=sk-your-api-key-here
OPENAI_BASE_URL=https://newapi.deepwisdom.ai/v1
OPENAI_MODEL=gpt-4o

# Optional: LLM provider selection (currently only supports openai)
LLM_PROVIDER=openai

# Optional: Storage path override
WEFINANCE_STORAGE_FILE=/custom/path/to/data.json
```

**Template file**: `.env.example` (copy to `.env` and fill in your API key)

**Security**:
- `.env` is git-ignored
- Never commit API keys to version control
- Loaded via `python-dotenv` in all services

### Conda Environment

**Python Version**: 3.10.x (specified in `environment.yml`)

**Why Conda**:
- Isolates scientific computing dependencies (numpy, pandas, scipy, opencv)
- Consistent environment across development machines

**Key Dependencies** (from requirements.txt):
- **Web Framework**: streamlit>=1.37,<2.0
- **LLM**: openai>=1.45.0, langchain>=0.2.10, langchain-openai>=0.1.7
- **Data**: pandas>=2.0, numpy>=1.26, scikit-learn>=1.4
- **Visualization**: plotly>=5.18
- **Models**: pydantic>=2.0
- **Utils**: python-dotenv>=1.0, pillow>=10.0

**IMPORTANT**: Always activate environment before running any command:
```bash
conda activate wefinance
```

**Updating dependencies**:
1. Modify `environment.yml` or `requirements.txt`
2. Run `conda env update -f environment.yml --prune`
3. Test all functionality locally
4. Commit changes to trigger Streamlit Cloud auto-redeploy
5. Verify deployment on https://wefinance-copilot.streamlit.app

**Important**: Streamlit Cloud reads `requirements.txt`, not `environment.yml`. Ensure dependencies are also listed in `requirements.txt` for cloud deployment.

## Common Pitfalls

### 1. Forgetting to Activate Conda Environment
```bash
# WRONG: Uses system Python, missing packages
python test_vision_ocr.py

# CORRECT: Activates environment first
conda activate wefinance
python test_vision_ocr.py
```

**Symptoms**: `ModuleNotFoundError: No module named 'streamlit'`

### 2. Breaking Session State Consistency
```python
# WRONG: Direct manipulation bypasses validation
st.session_state["transactions"] = new_data

# CORRECT: Use helper functions from utils/session.py
from utils.session import set_transactions
set_transactions(new_data)
```

**Why helpers matter**: Ensures Transaction ‚Üí dict serialization, type safety, validation.

### 3. Ignoring Vision OCR JSON Parsing

The Vision LLM sometimes wraps JSON in markdown code blocks:
```
```json
[{"date": "2025-11-01", ...}]
```
```

The code in `vision_ocr_service.py:123-131` handles this automatically. Don't bypass it.

### 4. Testing Without Sample Data

Use `assets/sample_bills/` for testing, not random images.

**Synthetic bills** (for automated testing):
- **bill_dining.png**: 4 dining transactions
- **bill_mixed.png**: 4 mixed-category transactions
- **bill_shopping.png**: 3 shopping transactions
- Generated with `generate_sample_bills.py` using Noto CJK fonts

**Real bills** (for production validation):
- Located in `assets/sample_bills/real/` (1.jpg, 2.png, 3.png, 4.png)
- Actual photos/scans for realistic testing scenarios
- Use these to verify Vision OCR works with real-world image quality variations
- **Important**: These are actual bill images and should not be committed to public repos without sanitization

### 5. Modifying Transaction Model Without Migration

`models/entities.py::Transaction` is used everywhere. Adding/removing fields requires:
1. Update model with default values for backward compatibility
2. Update all consumers (chat, analysis, recommendations, anomaly detection)
3. Update tests (integration tests will break)
4. Run full test suite: `pytest tests/ -v`

**Transaction model fields** (as of 2025-11-06):
- `id`: str
- `date`: str (YYYY-MM-DD format)
- `merchant`: str
- `category`: str (È§êÈ•Æ„ÄÅ‰∫§ÈÄö„ÄÅË¥≠Áâ©„ÄÅÂ®±‰πê„ÄÅÂåªÁñó„ÄÅÊïôËÇ≤„ÄÅÂÖ∂‰ªñ)
- `amount`: float

### 6. Not Using Error Handling Utilities

**WRONG**: Raw API calls without protection
```python
def chat(query):
    response = openai.chat.completions.create(...)  # No timeout, no error handling
    return response.choices[0].message.content
```

**CORRECT**: Use @safe_call decorator
```python
from utils.error_handling import safe_call

@safe_call(timeout=15, fallback="Êä±Ê≠âÔºåÊöÇÊó∂Êó†Ê≥ïÂõûÁ≠î")
def chat(query):
    response = openai.chat.completions.create(...)
    return response.choices[0].message.content
```

## Architecture Decisions Log

### 2025-11-15: Vision OCR Multi-line Recognition Enhancement

**Problem**: LLM only recognized the first transaction in multi-row bills, merging multiple transactions into one record.

**Root Cause Analysis** (Linus-style thinking):
- Issue wasn't token limits or temperature settings
- LLM wasn't understanding "process each line" instruction
- Problem was in data structure/thinking process, not code logic

**Solution**: Applied "fix data structure, not logic" principle
- Modified prompt to force LLM to **count first, then extract**:
  ```
  ‚òÖ È¶ñÂÖàÁªüËÆ°ÂõæÁâá‰∏≠ÊúâÂ§öÂ∞ëÁ¨î‰∫§ÊòìÔºàÊúâÂá†Ë°åÁã¨Á´ãÈáëÈ¢ùÂ∞±ÊúâÂá†Á¨î‰∫§ÊòìÔºâ
  ‚òÖ ÁÑ∂ÂêéÈÄêË°åÊèêÂèñÊØè‰∏ÄÁ¨îÁöÑËØ¶ÁªÜ‰ø°ÊÅØÔºåÁ°Æ‰øù transactions Êï∞ÁªÑÈïøÂ∫¶ = transaction_count
  ```
- Introduced `{transaction_count, transactions}` format (with backward compatibility for old format)
- This makes LLM focus on "how many rows" before processing details

**Impact**:
- Recognition success rate: 30% (3/10 images) ‚Üí **100% (10/10 images)**
- Multi-row bills perfectly recognized:
  - bill_dining.png: 1/4 ‚Üí 4/4
  - bill_shopping.png: 1/3 ‚Üí 3/3
  - real/4.png: 1/4 ‚Üí 4/4
- Real-world payment app screenshots: 7-12 transactions correctly identified
- Zero changes to parsing logic (backward compatible)

**Files Changed**:
- MODIFIED: `services/vision_ocr_service.py` (lines 220-223 prompt structure, lines 351-370 parsing logic)
- NEW: `scripts/test_vision_ocr.py` (batch validation script with metadata support)
- MODIFIED: `assets/sample_bills/metadata.json` (added expected_transactions for validation)

**Testing**:
- Test command: `python scripts/test_vision_ocr.py --show-details --dump-json`
- Results logged to: `artifacts/ocr_test_results.log`
- JSON dumps: `artifacts/ocr_results/*.json`

**Key Insight** (Linus philosophy):
> "Bad programmers worry about the code. Good programmers worry about data structures."
>
> By changing how we ask LLM to structure its thinking (count ‚Üí extract), the multi-line recognition problem solved itself. No need for complex heuristics or post-processing.

### 2025-11-09: Error Handling & Storage Systems

**Problem**: No unified error handling, no persistent storage across sessions.

**Solution**:
- Added `utils/error_handling.py` with @safe_call decorator and UserFacingError
- Added `utils/storage.py` for file-based persistence

**Impact**:
- Better UX: User-friendly error messages instead of technical stack traces
- Timeout protection: All LLM calls now have 15-30s timeouts
- Data persistence: User preferences survive browser refreshes
- Code simplification: Consistent error handling pattern across codebase

**Files Changed**:
- NEW: `utils/error_handling.py` (166 lines)
- NEW: `utils/storage.py` (147 lines)
- NEW: `tests/test_error_handling.py`
- NEW: `tests/test_storage.py`

### 2025-11-06: PaddleOCR ‚Üí GPT-4o Vision

**Problem**: PaddleOCR couldn't recognize synthetic bill images (0% accuracy on `generate_sample_bills.py` output).

**Solution**: Replaced with GPT-4o Vision, achieving 100% accuracy.

**Impact**:
- **Completely removed** PaddlePaddle/PaddleOCR dependencies (2025-11-11)
- Simplified pipeline from 2-step to 1-step
- Increased API cost (~$0.01/image) but acceptable for MVP/competition
- Improved accuracy from 0% to 100% on synthetic images

**Files Changed**:
- NEW: `services/vision_ocr_service.py` (161 lines)
- MODIFIED: `services/ocr_service.py` (now delegates to VisionOCRService)
- REMOVED: PaddleOCR dependencies from `environment.yml`, `requirements.txt`, `.env.example`

**Migration path**: All code uses `OCRService` facade, which internally delegates to `VisionOCRService`.

## Demo Materials (NEW - 2025-11-09)

**Location**: `screenshots/` and `demo/`

### Screenshots for Competition Submission

**Chinese UI** (screenshots/):
- `01_homepage_progress_zh.png`: Homepage with feature overview
- `02_bill_upload_ocr_zh.png`: Bill upload and OCR results
- `03_spending_insights_zh.png`: Spending analysis dashboard
- `04_advisor_chat_zh.png`: AI financial advisor conversation
- `05_investment_recs_zh.png`: Investment recommendations with XAI
- `06_sidebar_zh.png`: Navigation sidebar

**English UI** (screenshots/):
- `07_homepage_progress_en.png`: English homepage
- `08_advisor_chat_en.png`: English chat interface

**Usage**: Include in competition presentation and documentation.

### Presentation Materials (demo/)

**Files**:
- `wefinance_presentation.pptx`: Competition presentation slides
- `video_script.md`: Video demonstration script
- `ppt_outline.md`: Presentation structure outline
- `checklist.md`: Pre-submission checklist

**Note**: PowerPoint generation scripts (`create_ppt_*.js`) use Node.js and officegen package.

## Debugging Tips

### Vision OCR Not Working

1. Check `.env` has valid `OPENAI_API_KEY`
2. Test API connectivity: `python test_vision_ocr.py`
3. Check logs: `services/vision_ocr_service.py` logs at INFO level
4. Verify image format: PNG/JPG/JPEG only (PDF not supported by Vision API)
5. Check API rate limits: `https://newapi.deepwisdom.ai/v1` may have limits

**Common errors**:
- `ValueError: OPENAI_API_KEY environment variable not set`: Missing/invalid `.env` file
- `UserFacingError: APIÂØÜÈí•ÈÖçÁΩÆÈîôËØØ`: Invalid API key or authentication failure
- `UserFacingError: Êìç‰ΩúË∂ÖÊó∂`: Network timeout (check internet connection)
- Empty transaction list: Image might not contain recognizable bill data

### Streamlit Session State Issues

1. Check `utils/session.py` for state initialization: `init_session_state()` called in `app.py`
2. Use `st.session_state` debugger: Add `st.write(st.session_state)` temporarily
3. Verify state keys match between pages: Use constants from `utils/session.py::DEFAULT_STATE`
4. Check session persistence: Session state resets on browser refresh (expected behavior)
5. Use `utils/storage.py` for data that should persist across sessions

**Common issues**:
- `KeyError: 'transactions'`: `init_session_state()` not called before access
- Data not persisting: Check if using helper functions, not direct dict access
- Locale not switching: Missing `st.rerun()` after `switch_locale()`

### LLM Timeout/Failure

1. Check API rate limits: `https://newapi.deepwisdom.ai/v1` dashboard
2. Verify network connectivity to OpenAI-compatible endpoint
3. Review error logs: UserFacingError provides user-friendly context
4. Check API key validity: Test with `curl` or `python test_vision_ocr.py`

**Graceful degradation**:
- Vision OCR: Returns empty list via @safe_call(fallback=[])
- Chat: Returns error message via @safe_call(fallback="Êä±Ê≠â...")
- Recommendations: Returns empty list, shows UserFacingError message

### Storage Issues

1. Check storage file location: `~/.wefinance/data.json` or workspace fallback
2. Verify write permissions: Storage auto-falls back to workspace if home is unwritable
3. Check JSON format: Invalid JSON corrupts storage (handled gracefully)
4. Clear corrupted storage: Delete `~/.wefinance/data.json` manually

**Common issues**:
- `PermissionError`: Fallback to workspace storage (check logs)
- Data not persisting: Check `save_to_storage()` return value (bool)
- Corrupted JSON: `_load_all()` returns empty dict on parse failure

## Performance Considerations

### LLM API Calls

- **Vision OCR**: ~2-5 seconds per image (acceptable for demo, limits to 10 images/upload)
- **Chat**: ~1-3 seconds per message (cached queries return instantly)
- **Recommendations**: ~3-7 seconds (cached by input hash via `@st.cache_data`)
- **Timeouts**: All calls protected by @safe_call (30s vision, 15s chat/recommendations)

**Optimization opportunities**:
- Implement progressive loading for long transaction lists
- Pre-cache common queries on startup (e.g., "ÊàëËøô‰∏™ÊúàËøòËÉΩËä±Â§öÂ∞ëÔºü")
- Batch multiple images in single Vision API call (if API supports)

### Caching Strategy

1. **Query-level** (`chat_manager.py`): LRU cache for exact query matches (20 items)
2. **Deterministic inputs** (`@st.cache_data`): Recommendation generation (transaction hash)
3. **Session state**: All transaction data lives in session, not re-fetched
4. **Persistent storage** (`storage.py`): User preferences, trusted merchants (file-based)

**Cache invalidation**:
- Chat cache: Cleared on locale switch (different language = different response)
- `@st.cache_data`: Cleared automatically by Streamlit on input change
- Session state: Persists until browser refresh or explicit reset
- Storage: Persists until manual deletion or `clear_all_storage()`

### Streamlit Optimization

**Current performance**:
- Initial page load: ~2-3 seconds (includes I18n initialization)
- Page navigation: <1 second (session state persists)
- OCR upload: 2-5 seconds per image (API call)

**Best practices**:
- Use `@st.cache_data` for expensive computations
- Avoid re-running entire app on every interaction (use callbacks)
- Limit number of widgets per page (current: ~10-15 per page)

## Security Notes

### API Key Management

- **NEVER** commit `.env` file to version control
- Use `.env.example` as template for other developers
- API keys loaded via `python-dotenv` in all services
- Validate API key presence at service initialization (raises `ValueError` if missing)
- Error handling masks API key details in user-facing messages

### Input Validation

- **Transaction amounts**: Validated in Pydantic models (`models/entities.py`)
- **File uploads**: Limited to PNG/JPG in Streamlit uploader (`accept_multiple_files=True`)
- **User inputs**: Sanitized before LLM prompts (no injection attacks)
- **Date format**: Validated via regex in Transaction model

### Privacy

- **Images**: Processed locally (base64 encoded for API call), not stored permanently
- **Transactions**: Stored in session state only (cleared on browser refresh)
- **Persistent data**: Stored in local JSON file (~/.wefinance/data.json), no cloud upload
- **LLM provider**: `newapi.deepwisdom.ai` may log API calls - inform users in production
- **No database**: Zero cloud storage = zero data breach risk for MVP
- **Storage encryption**: Not implemented (local file is unencrypted JSON)

## Project Structure

```
WeFinance/
‚îú‚îÄ‚îÄ app.py                      # Streamlit entry point
‚îú‚îÄ‚îÄ environment.yml             # Conda environment (Python 3.10 + dependencies)
‚îú‚îÄ‚îÄ requirements.txt            # pip dependencies (latest versions)
‚îú‚îÄ‚îÄ .env.example               # Environment variable template
‚îú‚îÄ‚îÄ .env                       # Environment variables (git-ignored)
‚îÇ
‚îú‚îÄ‚îÄ pages/                     # Streamlit pages (one file = one navigation item)
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ bill_upload.py         # Upload bills, run Vision OCR
‚îÇ   ‚îú‚îÄ‚îÄ spending_insights.py   # Consumption analysis, anomaly detection
‚îÇ   ‚îú‚îÄ‚îÄ advisor_chat.py        # AI financial advisor chat
‚îÇ   ‚îî‚îÄ‚îÄ investment_recs.py     # Explainable investment recommendations
‚îÇ
‚îú‚îÄ‚îÄ modules/                   # Core business logic
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ analysis.py           # Data analysis, anomaly detection algorithms
‚îÇ   ‚îî‚îÄ‚îÄ chat_manager.py       # Chat context assembly, LLM call, caching
‚îÇ
‚îú‚îÄ‚îÄ services/                  # AI service layer
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ vision_ocr_service.py  # GPT-4o Vision OCR (core innovation)
‚îÇ   ‚îú‚îÄ‚îÄ ocr_service.py         # OCR facade (delegates to VisionOCRService)
‚îÇ   ‚îú‚îÄ‚îÄ structuring_service.py # Legacy GPT-4o structuring (deprecated)
‚îÇ   ‚îú‚îÄ‚îÄ recommendation_service.py # Investment recommendation generation
‚îÇ   ‚îî‚îÄ‚îÄ langchain_agent.py     # LangChain agent wrapper (optional)
‚îÇ
‚îú‚îÄ‚îÄ models/                    # Data models (Pydantic)
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ entities.py           # Transaction, UserProfile, etc.
‚îÇ
‚îú‚îÄ‚îÄ utils/                     # Utilities
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ session.py            # Session state helpers (CRITICAL)
‚îÇ   ‚îú‚îÄ‚îÄ i18n.py               # Internationalization engine
‚îÇ   ‚îú‚îÄ‚îÄ error_handling.py     # Unified error handling
‚îÇ   ‚îú‚îÄ‚îÄ storage.py            # File-based persistence
‚îÇ   ‚îî‚îÄ‚îÄ ui_components.py      # Reusable UI components (NEW)
‚îÇ
‚îú‚îÄ‚îÄ locales/                   # Translation files
‚îÇ   ‚îú‚îÄ‚îÄ zh_CN.json            # Chinese translations
‚îÇ   ‚îî‚îÄ‚îÄ en_US.json            # English translations
‚îÇ
‚îú‚îÄ‚îÄ tests/                     # Test suite (pytest)
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ test_integration.py    # End-to-end scenarios
‚îÇ   ‚îú‚îÄ‚îÄ test_ocr_service.py    # Vision OCR tests
‚îÇ   ‚îú‚îÄ‚îÄ test_chat_manager.py   # Chat manager tests
‚îÇ   ‚îú‚îÄ‚îÄ test_session_state.py  # Session state tests
‚îÇ   ‚îú‚îÄ‚îÄ test_error_handling.py # Error handling tests (NEW)
‚îÇ   ‚îú‚îÄ‚îÄ test_storage.py        # Storage tests (NEW)
‚îÇ   ‚îú‚îÄ‚îÄ test_structuring_service.py # Legacy tests
‚îÇ   ‚îî‚îÄ‚îÄ test_i18n.py           # i18n tests
‚îÇ
‚îú‚îÄ‚îÄ assets/                    # Static assets
‚îÇ   ‚îî‚îÄ‚îÄ sample_bills/          # Sample bill images for testing
‚îÇ       ‚îú‚îÄ‚îÄ bill_dining.png    # Synthetic: 4 dining transactions
‚îÇ       ‚îú‚îÄ‚îÄ bill_mixed.png     # Synthetic: 4 mixed categories
‚îÇ       ‚îú‚îÄ‚îÄ bill_shopping.png  # Synthetic: 3 shopping transactions
‚îÇ       ‚îî‚îÄ‚îÄ real/              # Real bill photos (production testing)
‚îÇ           ‚îú‚îÄ‚îÄ 1.jpg
‚îÇ           ‚îú‚îÄ‚îÄ 2.png
‚îÇ           ‚îú‚îÄ‚îÄ 3.png
‚îÇ           ‚îî‚îÄ‚îÄ 4.png
‚îÇ
‚îú‚îÄ‚îÄ screenshots/               # Demo materials for competition (NEW)
‚îÇ   ‚îú‚îÄ‚îÄ 01_homepage_progress_zh.png
‚îÇ   ‚îú‚îÄ‚îÄ 02_bill_upload_ocr_zh.png
‚îÇ   ‚îú‚îÄ‚îÄ 03_spending_insights_zh.png
‚îÇ   ‚îú‚îÄ‚îÄ 04_advisor_chat_zh.png
‚îÇ   ‚îú‚îÄ‚îÄ 05_investment_recs_zh.png
‚îÇ   ‚îú‚îÄ‚îÄ 06_sidebar_zh.png
‚îÇ   ‚îú‚îÄ‚îÄ 07_homepage_progress_en.png
‚îÇ   ‚îî‚îÄ‚îÄ 08_advisor_chat_en.png
‚îÇ
‚îú‚îÄ‚îÄ demo/                      # Presentation materials (NEW)
‚îÇ   ‚îú‚îÄ‚îÄ wefinance_presentation.pptx
‚îÇ   ‚îú‚îÄ‚îÄ video_script.md
‚îÇ   ‚îú‚îÄ‚îÄ ppt_outline.md
‚îÇ   ‚îî‚îÄ‚îÄ checklist.md
‚îÇ
‚îú‚îÄ‚îÄ .claude/                   # Project documentation
‚îÇ   ‚îú‚îÄ‚îÄ PROJECT_RULES.md       # Claude Code ‚Üî Codex collaboration rules
‚îÇ   ‚îî‚îÄ‚îÄ specs/
‚îÇ       ‚îî‚îÄ‚îÄ wefinance-copilot/
‚îÇ           ‚îú‚îÄ‚îÄ 00-repo-scan.md
‚îÇ           ‚îú‚îÄ‚îÄ 01-product-requirements.md
‚îÇ           ‚îú‚îÄ‚îÄ 02-system-architecture.md
‚îÇ           ‚îî‚îÄ‚îÄ 03-sprint-plan.md
‚îÇ
‚îú‚îÄ‚îÄ generate_sample_bills.py   # Generate Chinese sample bills
‚îú‚îÄ‚îÄ generate_sample_bills_english.py # Generate English sample bills
‚îî‚îÄ‚îÄ test_vision_ocr.py         # Manual Vision OCR testing script
```

## Git Workflow

### Branch Strategy

**Main Branch**: `main` (production-ready, auto-deploys to Streamlit Cloud)

**Development Flow**:
```bash
# Create feature branch
git checkout -b feature/your-feature-name

# Make changes, test locally
streamlit run app.py
pytest tests/ -v

# Format and lint
black .
ruff check --fix .

# Commit with conventional commit format (NO emoji, NO Claude footer)
git commit -m "feat(ocr): improve Vision OCR error handling"
git commit -m "fix(chat): resolve cache invalidation on locale switch"
git commit -m "docs: update deployment guide with K8s instructions"

# Push and create PR
git push origin feature/your-feature-name
# Create PR on GitHub targeting main branch

# After PR approval, merge to main
# Streamlit Cloud auto-deploys within 2-3 minutes
```

**Commit Message Format** (see global CLAUDE.md):
- ‚úÖ Use conventional commits: `type(scope): description`
- ‚úÖ Types: `feat`, `fix`, `docs`, `chore`, `refactor`, `test`, `perf`
- ‚ùå NO emoji in commit messages
- ‚ùå NO "Generated with Claude Code" footer
- ‚ùå NO "Co-Authored-By: Claude" footer

**Pre-commit Checklist**:
- [ ] All tests pass: `pytest tests/ -v`
- [ ] Code formatted: `black .`
- [ ] Linting clean: `ruff check .`
- [ ] Local app runs: `streamlit run app.py`
- [ ] No `.env` file committed (use `.env.example`)
- [ ] API keys removed from code
- [ ] Commit message follows conventional format

### Deployment Status Check

After merging to `main`:
1. Visit https://share.streamlit.io/ (Streamlit Cloud Dashboard)
2. Check deployment status (should show "Building..." ‚Üí "Running")
3. Wait 2-3 minutes for build completion
4. Test live app at https://wefinance-copilot.streamlit.app
5. If deployment fails, check logs in Dashboard ‚Üí Logs
6. Common failure causes:
   - Missing dependencies in `requirements.txt`
   - Secrets not configured in Streamlit Cloud
   - Import errors (test locally first)

## For More Information

- **Live Demo**: https://wefinance-copilot.streamlit.app
- **Project Overview**: See README.md (English) or README_zh-CN.md (Chinese)
- **Deployment Guide**: See DEPLOY.md
- **Repository Guidelines**: See AGENTS.md (Chinese guidelines for structure, testing, commits)
- **Collaboration Rules**: See `.claude/PROJECT_RULES.md`
- **System Architecture**: See `.claude/specs/wefinance-copilot/02-system-architecture.md`
- **Product Requirements**: See `.claude/specs/wefinance-copilot/01-product-requirements.md`
- **Sprint Planning**: See `.claude/specs/wefinance-copilot/03-sprint-plan.md`
- **Demo Checklist**: See `demo/checklist.md`
