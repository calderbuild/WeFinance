"""Investment recommendation and explainability view."""

from __future__ import annotations

from typing import Dict, Iterable, List, Tuple

import pandas as pd
import plotly.express as px
import streamlit as st

from models.entities import Recommendation, Transaction
from services.recommendation_service import RecommendationService

RISK_QUESTIONS: List[Dict[str, object]] = [
    {
        "id": "q1",
        "prompt": "æ‚¨èƒ½æ¥å—çš„æœ€å¤§äºæŸæ˜¯å¤šå°‘ï¼Ÿ",
        "options": [
            ("5%ä»¥å†…ï¼Œå‡ ä¹ä¸èƒ½äºæŸ", 1),
            ("10%å·¦å³ï¼Œå¯æ¥å—ä¸€å®šæ³¢åŠ¨", 2),
            ("20%ä»¥ä¸Šï¼Œåªè¦é•¿æœŸæœ‰æ”¶ç›Š", 3),
        ],
    },
    {
        "id": "q2",
        "prompt": "æ‚¨çš„æŠ•èµ„æœŸé™æ˜¯å¤šä¹…ï¼Ÿ",
        "options": [
            ("1å¹´ä»¥å†…ï¼Œéœ€è¦èµ„é‡‘çš„æµåŠ¨æ€§", 1),
            ("1-3å¹´ï¼Œå¯ä»¥é˜¶æ®µæ€§é”å®šèµ„é‡‘", 2),
            ("3å¹´ä»¥ä¸Šï¼Œé•¿æœŸå¢å€¼ä¸ºä¸»", 3),
        ],
    },
    {
        "id": "q3",
        "prompt": "æ‚¨å¯¹æŠ•èµ„æ³¢åŠ¨çš„æ€åº¦å¦‚ä½•ï¼Ÿ",
        "options": [
            ("æ³¢åŠ¨è®©æˆ‘ç„¦è™‘ï¼Œå°½é‡é¿å…", 1),
            ("é€‚åº¦æ³¢åŠ¨å¯ä»¥æ¥å—", 2),
            ("æ³¢åŠ¨è¶Šå¤§è¶Šæœ‰æœºä¼š", 3),
        ],
    },
]


def _coerce_transactions(transactions_raw: Iterable[object]) -> List[Transaction]:
    normalized: List[Transaction] = []
    for entry in transactions_raw:
        if isinstance(entry, Transaction):
            normalized.append(entry)
        elif isinstance(entry, dict):
            normalized.append(Transaction(**entry))
    return normalized


@st.cache_data(show_spinner=False)
def _generate_cached_recommendation(
    transactions_dump: Tuple[Tuple[Tuple[str, object], ...], ...],
    responses_tuple: Tuple[Tuple[str, int], ...],
    goal: str,
) -> Dict[str, object]:
    """Cacheable wrapper producing recommendation payload."""
    service = RecommendationService()
    transactions = [Transaction(**dict(entry)) for entry in transactions_dump]
    responses = dict(responses_tuple)
    return service.generate(
        transactions=transactions,
        responses=responses,
        investment_goal=goal,
    )


def _collect_risk_answers() -> Tuple[Dict[str, int], str]:
    st.subheader("Step 1ï¼šé£é™©åå¥½è¯„ä¼°")
    answers: Dict[str, int] = {}
    for question in RISK_QUESTIONS:
        key = f"risk_{question['id']}"
        label = question["prompt"]
        options: List[Tuple[str, int]] = question["options"]  # type: ignore[assignment]
        labels = [opt[0] for opt in options]
        default_index = 0
        selected = st.radio(label, options=labels, index=default_index, key=key, horizontal=False)
        for opt_label, score in options:
            if opt_label == selected:
                answers[question["id"]] = score
                break

    st.subheader("Step 2ï¼šå¡«å†™æŠ•èµ„ç›®æ ‡")
    goal = st.text_input(
        "è¯·æè¿°æ‚¨çš„ç›®æ ‡ï¼ˆç¤ºä¾‹ï¼š\"æˆ‘æƒ³åœ¨3å¹´å†…å­˜20ä¸‡ä¹°è½¦\"ï¼‰",
        placeholder="è¯·è¾“å…¥æŠ•èµ„ç›®æ ‡ã€é‡‘é¢æˆ–æœŸé™",
        key="investment_goal",
    )
    return answers, goal


def _render_allocation_chart(allocation: Dict[str, float]) -> None:
    allocation_df = pd.DataFrame(
        {"èµ„äº§ç±»å‹": list(allocation.keys()), "å æ¯”": [value * 100 for value in allocation.values()]}
    )
    fig = px.pie(
        allocation_df,
        names="èµ„äº§ç±»å‹",
        values="å æ¯”",
        title="èµ„äº§é…ç½®æ¯”ä¾‹",
        hole=0.35,
    )
    fig.update_traces(textposition="inside", textinfo="percent+label")
    st.plotly_chart(fig, use_container_width=True)


def _render_results(results: Dict[str, object]) -> None:
    recommendation: Recommendation = results["recommendation"]  # type: ignore[assignment]
    explanation: str = results["explanation"]  # type: ignore[assignment]
    metrics: Dict[str, float] = results["metrics"]  # type: ignore[assignment]
    allocation: Dict[str, float] = results["allocation"]  # type: ignore[assignment]
    risk_level: str = results["risk_level"]  # type: ignore[assignment]

    st.success(f"é£é™©åå¥½è¯„ä¼°ç»“æœï¼š**{risk_level}**")
    st.markdown(f"**æ ¸å¿ƒå»ºè®®**ï¼š{recommendation.summary}")

    st.subheader("èµ„äº§é…ç½®æ–¹æ¡ˆ")
    _render_allocation_chart(allocation)

    st.subheader("é¢„æœŸæ”¶ç›Šä¸é£é™©æŒ‡æ ‡")
    col1, col2 = st.columns(2)
    with col1:
        st.metric("é¢„æœŸå¹´åŒ–æ”¶ç›Š", f"{metrics['expected_return']:.1f}%")
    with col2:
        st.metric("æœ€å¤§å›æ’¤ï¼ˆå†å²æ¨¡æ‹Ÿï¼‰", f"{metrics['max_drawdown']:.1f}%")

    st.subheader("æ‰§è¡Œå»ºè®®ä¸è¡ŒåŠ¨æ­¥éª¤")
    for idx, step in enumerate(recommendation.rationale_steps, start=1):
        st.write(f"{idx}. {step}")

    with st.expander("ä¸ºä»€ä¹ˆæ¨èè¿™ä¸ªç»„åˆï¼Ÿï¼ˆXAIè§£é‡Šï¼‰", expanded=False):
        st.markdown(explanation.replace("\n", "  \n"))


def render() -> None:
    """Render investment recommendation workflow with XAI explanation."""
    st.title("ğŸ’¡ ç†è´¢å»ºè®®ä¸å¯è§£é‡Šæ€§")
    st.write("é€šè¿‡é£é™©è¯„ä¼°ä¸ç›®æ ‡è®¾å®šï¼Œä¸ºæ‚¨ç”Ÿæˆä¸ªæ€§åŒ–çš„èµ„äº§é…ç½®æ–¹æ¡ˆï¼Œå¹¶ç»™å‡ºå†³ç­–è§£é‡Šã€‚")

    transactions_raw = st.session_state.get("transactions", [])
    transactions = _coerce_transactions(transactions_raw)

    answers, goal = _collect_risk_answers()
    responses_tuple = tuple(sorted(answers.items()))
    transactions_dump = tuple(
        tuple(sorted(tx.model_dump().items(), key=lambda item: item[0]))
        for tx in transactions
    )

    st.subheader("Step 3ï¼šç”Ÿæˆèµ„äº§é…ç½®å»ºè®®")
    if st.button("ç”Ÿæˆç†è´¢å»ºè®®", type="primary"):
        try:
            with st.spinner("æ­£åœ¨ç”Ÿæˆä¸ªæ€§åŒ–é…ç½®ï¼Œè¯·ç¨å€™..."):
                results = _generate_cached_recommendation(
                    transactions_dump,
                    responses_tuple,
                    goal,
                )
        except Exception as exc:  # pylint: disable=broad-except
            st.error(f"ç”Ÿæˆæ¨èå¤±è´¥ï¼š{exc}")
            return

        _render_results(results)
        # Persist to session for downstream usage or export.
        st.session_state["product_recommendations"] = [
            results["recommendation"].model_dump()  # type: ignore[attr-defined]
        ]
        st.session_state["recommendation_explanation"] = results
    else:
        cached = st.session_state.get("recommendation_explanation")
        if cached:
            st.info("å·²åŠ è½½ä¸Šæ¬¡ç”Ÿæˆçš„ç†è´¢æ–¹æ¡ˆã€‚è°ƒæ•´å‚æ•°åå¯å†æ¬¡ç”Ÿæˆæ–°æ–¹æ¡ˆã€‚")
            _render_results(cached)
        else:
            st.info("å¡«å†™é—®å·å¹¶ç‚¹å‡»æŒ‰é’®åå°†ç”Ÿæˆä¸ªæ€§åŒ–èµ„äº§é…ç½®å»ºè®®ã€‚")
